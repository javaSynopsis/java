Note. В процессе редактирования.

# Common
Современное приложение на Java.

# Monolith
**шаги реализации**
1. Через idea и spring initializer создать проект с зависимостями
   1. spring data rest
   2. spring hal
   3. spring data jpa
   4. lombok
   5. spring security
   6. hal explorer
   7. spring dev tools
   8. для базы установить jdbc, connector
2. переименовать application.properties в application.yaml
3. настроить DB в application.yaml иначе приложение не поднимется
4. настроить отдельный профиль в отдельных файлах для production и поставить dev профиль по умолчанию
   1. в dev профиле включить доп. логирование
   2. профили spring замапить на профили maven
   3. dev профиль смотрит на hsql, prod профиль на MySQL
5. настроить отдельный профиль для наката default данных справочников
6. настроить liquibase
   1. пролив данных справочников сделать через csv файлы
7. вынести настройки lombok в отдельный файл в lombok.config
8. настроить интернациализацию messages.properties и создать отдельные файлы для каждого языка
9.  настроить лимиты БД на количество записей и запустить сервис их очистки (в приложении)
10. настроить работу с jwt по OAuth2
11. настроить spring session для хранения инфы в сессии если нужно
12. засунуть приложение в docker а точнее docker compose
13. подключить swagger для hal если нужно
14. настроить реверс прокси
15. тесты
    1.  написать junit тесты
    2.  написать интеграционные тесты
    3.  в postman написать коллекции тестов
16. анализ
    1.  подключить zipkin для мониторинга
    2.  настроить kibana
    3.  настроить spring actuator или аналогичный инструмент

**если hal окажется сложным**
* использовать map struct и наделать dto
* над dto проставить hibernate validator проверки

**структура**
* core - общие предки
* pieces - куски сущностей со своими сервисами и контроллерами
* configuration - конфиги разных частей приложения

# Microserves application
1. Разработка
   1. Eureka
   2. Zuul
   3. Kafka & zookeeper
   4. Fein
   5. Lombok
   6. Hibernate ORM
   7. Hibernate Valitator
   8. Postgres
   9. zipkin2 - система распределенной трасировки, которая показывает логи выполнения методов и их время, в том числе в UI; чтобы логи видеть службы (код) нужно анатировать чтобы включить их анализ https://www.baeldung.com/tracing-services-with-zipkin
   10. swagger
   11. orika (но это неэффективнй mapper, mapstruct лучше) - для маппинга в dto https://www.baeldung.com/orika-mapping
   12. Kubernates - для оркестровки образами в продакшене
       1.  Helm это пакетный менеджер для Kubernetes, который позволяет управлять всеми объектами (deployment, configmap, service etc) как одним целым, по аналогии с пакетами в linux. При использовании helm возможно ставить приложение в любой кластер без использования jenkins и прочих инструментов ci-cd.
   13. Docker и kitematic - для удобного разварачивания образов на десктопе
   14. docker compose - формирует набор docker образов связанных друг с другом (общающихся) и запускающихся в определенном порядке (прим. при запуске в kitematic нужно определить порядок запуска)
   15. Elastic
   16. kibana - показ логов и анализа данных в том числе в виде графики
   17. nginx - стоит до Zuul для балансирования нагрузки
   18.  Elasticsearch, Logstash и Kibana (ELK) - стэк для сбора и визуализации логов
   19.  IBM MQ - использован не факт
   20.  Prometheus - 
   21.  quartz - для  выполнения job по графику
   22.  spring batch - для выполнения job
   23.  библиотека для просмотра параметров hibernate https://www.mkyong.com/hibernate/how-to-display-hibernate-sql-parameter-values-solution/
   24.  для теста не на in memory базах, реальные базы поднимаются тестами в контейнерах через Testcontainers https://www.baeldung.com/spring-boot-testcontainers-integration-test
   25.  mini kube - тоже может использоваться например для быстрого развертывания для разработки
   26.  docker container - библиотечка которая может подключаться в тестах и поднимать тестовую базу, т.к. h2 и прочие не поддерживают специфичных фич (яндекс рекомендует именно это), поднятый docker container переиспользуется в других тестах, а не поднимается заново
   27.  gerrit - сервер для git, неудобнее чем gitlab, работа с ним происходит через плагин ide
   28.  Вместо стэка от Netflix (Eureka и Histrix) можно использовать стэк Istio от Google и IBM
   29.  Fortify
2. IDE
   1. Idea
   2. Copirights поле с описанием прав на созданные файлы в комментах
   3. настраиваем file headers - авторство кода добавляемое к файлу
   4. плагины
      1. checkstyle - указываем файл правил
      2. gerrit - указываем сервис gerrit с указанием дополнительных прав доступа
      3. sonarlint - указываем сервер правил sonarqube
   5. Настраиваем правила imports, причем imports спец. либ проекта стоят вторыми по счету после import static
3. Структура микросервиса
   1. каждый микросервис запускается в docker
   2. в модуле есть под-модули maven: api, db, impl, lib; в каждом из них есть свой каталог src/main и resources и target куда все собирается. каждый из этих модулей может использоваться в других микросервисах и поэтому выделены в отдельные под-модули
   3. api под-модуль содержит feign и его dto чтобы если dto или api с такой же сигнатурой используется в другом микросервисе (например вызов другим микросервисом этого же по тому же api) можно было просто подключить этот модуль.
   4. db содержит скрипты liquibase; тут же в resources каталоге могут быть другие (например cvs) файлы которые используются в sql
   5. impl содержит все остальное, сервисы, entities, configurations, utils; сюда же вынесен каталог resources; при этом в impl также содержится например реализация интерфейсов RestController из api подмодуля проекта (т.е. в api интерфейсы с RequestMapping, а в impl их реализация помеченная RestController)
   6. mymicroservice-lib-blabla используется как просто библиотека которая может быть нужна для других микросервисов 
   7. для работы микросервиса под нагрузкой используется стратегия семофор для feign которая обрабатывает запросы в одном потоке (note. как реверс проекси)
   8. для security у каждого сервиса есть пользователь (свой логин/пароль), это называется технический пользователь. Роли каждого микросервиса определяют к каким end points других микросервисов этот микросервис имеет доступ.
   9. Вместо Eureka + Zuul можно использовать инструменты kubernetes для discovery client и ribbon, например https://dzone.com/articles/quick-guide-to-microservices-with-kubernetes-sprin и https://github.com/spring-cloud/spring-cloud-kubernetes
   10. в проекте находится каталог log куда складываются логи
   11. в корне есть каталог helm с настройками для kubernetes
   12. в корне есть каталог environments с настройками для kubernetes (secrets например) и др.
   13. Репликация данных как вариант делается вручную через очереди kafka, т.е. если например сервис возвращает User (dto) с каким-то полем зависящим от поля Admin сущности другого сервиса, то 1ый сервис через kafka просит у 2го сервиса значение нужного поля Admin, а потом использует его в выражении вычисляющем значение своего поля User.
   14. В проекте перед первым deploy микросервиса нужно накатывать sql скрипты вручную, чтобы создать схему на которую потом liquibase накатит данные
   15. Микросервисы логически делятся на бизнес микросервисы с чисто бизнес логикой и остальные
   16. Какталог resource в api модуле играет роль controller из MVC
   17. resource - так называется пакет с контроллерами (которые тут называются resource и оканчиваются на `Resource`) и с Feign (классы оканчивающиеся на `...ResourceFeignClient` например `EmployeeResourceFeignClient`)
   18. На самом деле есть одна база прокся база patroni. За которой есть кластер баз. Все сервисы видят 1 базу.
   19. В микросервисе есть под модуль parent он родительский для ЧАСТИ других под модулей т.к. основной родительский в корне микросервиса. Этот модуль содержит часть properties, dependencyManagement и правил развертывания.
   20. Сегменты - это полные копии приложения со всеми его микросервисами. Чтобы оттестировать слепки сервисов определенных версий работающих вместе. При этом залогиненный пользователь в одном сегменте должен иметь доступ к другому и данные из одного сегмента должны быть доступны другому (т.е. какое-то взаимодействие с сегментами есть)
   21. структура каталога liquibase разделена на версии (каждый каталог - отдельная версия с корневым xml файлом конфигурации). В основной файл сделан include этих файлов версий
   22. дистрибутивные данные - это данные по умолчанию в DB, которыми наполняется DB при старте сервиса. Они хранятся в cvs файлах, новые версии файла заменяют старые и меняем id записи в конфигах liquibase чтобы "пролить" данные заново в DB. При этом тестовые данные которыми заполняется DB лежат в отдельном файле, при запуске в параметре maven передается путь к файлу который "проливать" в DB (тестовый или тот что для продакшена). Параметры liquibase это properties которые в модуле parent проекта.
   23. Над некоторыми custom exception классами проставлены @ResponseStatus аннотации и эти exceptions наследуют RuntimeException
   24. если в сервисе нужно чистить некоторые табл определенный промежуток времени, то создается job из quarts которая это делает
   25. Операции (или "бизнес операции") это объекты, могут быть view, modify, delete и прочие; т.е. например операция разрешенная пользователю это user_modify. Каждая операция может назначаться нескольким разным ролям, т.е. по сути к ролям прикреплен массив операций для которых они позволены. И в кастомных аннотациях проверки прав доступа происходят проверки этих прав.
       1.  Иногда обработка бизнес операций прикрепляется к контроллеру с помощью кастомной аннотации (т.е. указывается в аннотации над классом)
   26. Для миграции данных в проекте в каждом проекте микросервиса создается под-модуль (с определенным названием) и им наследуется абстрактные классы реализаций миграции данных из других сервисов или баз (самописные), при их запуски происходит переливание данных.
   27. В некоторых микросервисах для тестов может использоваться не docker container, а аналог из kubernetis лучше интегрированный с ним
   28. (это лично я не считаю правильным) Для фронта бэк по dto формирует мета-инфу (что-то вроде xsd для xml) по которому фронт получает доп. инфу о том как работать с json (в REST)
   29. enum используются часто, во всех списках, т.к. это и бизнес операции, и прочее что можно перечислить
   30. Холодные данные - устаревшие данные, которые стали неактуальными через какое-то время, отдельный микросервис переносит "устаревшие" данные в архивные таблицы
   31. integration - пакет проекта в котором listeners и senders для очередей сообщений из внешних сервисов (сами очереди могут иметь разных провайдеров: IBM MQ, RabbitMQ etc)
   32. Elastic stack используется как NoSQL база, данные из журнала аудита и других мест сразу сохраняются в нее (а не происходит индексация какой-то основной базы). Но это может быть особенностью конкретного проекта, в другом случае можно сделать основную базу и индексировать ее содержимое в elastic.
   33. kafka может использоваться для односторонней связи как своего рода хранилище, при этом репликация всех сохраненных сущеностей может происходить через HibernateListener во время commit транзакции. (Note. скорее всего это неудачное решение)
4. devops
   1. jira + confluens
   2. kanban доска с полями: ready to do, blocked, in progress, waiting, testing, complete
   3. Оценка задач проводится играрой в "покер" (каждый член команды ставит свою оценку) в спец. приложении, которое показывает статистику по оценке
5. Особенности кода проекта
   1. в configure для MVC есть проверка if на `auth=off` и тогда все end-point становятся разрешенными (permit all)
   2. использована библиотека https://github.com/tkaczmarzyk/specification-arg-resolver для декларативной работы со Specification
   3. Константы венесены в enum (строки используемые во многих местах)
   4. Idea ругается на слишком длинную команду запуска, поэтому в настройках запуска нужно изменить тип на classpath file (касается jdk 8)
   5. Проливание данных в DB сделано через плагин для maven для liquibase и доступно в IDE в разделе Plugins в меню сборки проекта через maven (2 раза кликнуть по записи liquibase:update)
   6. вместо мета модели для hibernate применяется аналог из lombok
6. Основные микросервисы
   1. auth - выдает токены внешним пользователями
   2. auth for internal users - выдает токены сервисами чтобы они могли логиниться друг в друга
   3. notification
   4. session - сервис управляет сессиями, у сессий есть доп. инфа, может например удалять сессии
   5. ACL - управление ролями
   6. справочники - сервис, который хранит данные (таблицы) и может отдавать их, если проект небольшой, то справочники можно хранить в микросервисе общих справочников, а в дальнейшем разбить его на много мелких справочников
   7. audit - аннотация проставленная над некоторыми методами оборачивает вызов в AOP и отправляет данные о том что метод вызван, кем, сколько времени работал и прочую инфу в этот сервис, который хранит журнал истории для аудита

# Валидация на клиенте и сервере одновременно
Можно использовать json schema для генерации вроде xsd для xml https://json-schema.org/implementations.html например https://github.com/victools/jsonschema-generator (пока сырой проект)